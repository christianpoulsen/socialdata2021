{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "\n",
    "Phew. Is it week 6 already? This week, we've gotten to the machine-learning part. There are lots of course on machine learning at DTU. And across many research areas, people use ML for all kinds of things. So there's a good chance you're already familiar with what's going to happen today. \n",
    "\n",
    "\n",
    "## The informal intro\n",
    "\n",
    "Here's the informal intro for today\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/OhsO4bsajds/0.jpg)](https://www.youtube.com/watch?v=OhsO4bsajds)\n",
    "\n",
    "As you know, I usually just record the video of me talking in an empty zoom room. Well, today I recorded a bit too close to another meeting, so the video features two unexpected guests :)\n",
    "\n",
    "## The plan for today\n",
    "\n",
    "So why are we working machine learning? Well, there are a number of reasons\n",
    "* Not all of you have done any machine learning, so this is a chance to make sure that everyone has had a chance to catch up.\n",
    "* And the second reason that I'd to get across in the course (and IMHO it's an important one) is that visualization **AND** machine learning is a powerful combination. A combination that is pretty rare. \n",
    "  - Usually it's the case that people are either good at machine learning or data viz, but not both. \n",
    "  - So what we will be able to do in this class is an unusual combo: We can use ML to understand data and then visualize the outputs of the machine-learning.\n",
    "\n",
    "To get started on all this, the idea for today is to give you a quick sense of machine-learning, the theory behind it and then get you guys ready to use the state-of-the-art machine learning framework for python, scikit-learn (`sklearn`).\n",
    "\n",
    "Thus, the elements are as follows.\n",
    "\n",
    "* Lightning intro to machine learning.\n",
    "* Playing around with `sklearn` through a couple of tutorials.\n",
    "* Then learning about the K nearest neighbors (KNN) algorithms, including an exercise based on the SF data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Lightning intro to machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we won't go too deep with machine learning in this class. Here there goal is to learn enough to combine data analysis with simple machine learning to create the next-level visualizations I advertised above.\n",
    "\n",
    "So we kick off the machine-learning part by watching some video lectures on the *fundamentals of Machine learning*. The lectures have been prepared by our very own expert, Ole Winter, whose work focuses on Machine Learning. The lectures + slides have been prepared especially for you guys by Ole, and lovingly edited by yours truly.\n",
    "\n",
    "**What is machine learning**\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/SsCYF9tDY9Y/0.jpg)](https://www.youtube.com/watch?v=SsCYF9tDY9Y)\n",
    "\n",
    "**Model selection**\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/MHhlAtw3Ces/0.jpg)](https://www.youtube.com/watch?v=MHhlAtw3Ces)\n",
    "\n",
    "**Feature extraction and selection**\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/RZmitKn220Q/0.jpg)](https://www.youtube.com/watch?v=RZmitKn220Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ole Winter, \"What is Machine Learning\" \n",
    "# from IPython.display import YouTubeVideo\n",
    "# YouTubeVideo(\"SsCYF9tDY9Y\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ole on Model Selection\n",
    "# YouTubeVideo(\"MHhlAtw3Ces\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ole on feature extraction and selection\n",
    "# YouTubeVideo(\"RZmitKn220Q\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to read a little bit about machine learning. For this written intro, we're going to use a book that I've used in this class in previous years. That book has a little bit of a special style. It focuses on learning everything from scratch ... and that includes defining mathematical concepts in code (rather than equations). It might take a little tiny bit of time to get used to. \n",
    "\n",
    "But it's a great book and a nice + concise intro that matches Ole's lectures pretty well. So here goes.\n",
    "\n",
    "*Reading*: Data Science From Scratch (DSFS), Chapter 11. It's on DTU Learn, under \"Lecture 6 reading\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercises*: A few questions about machine learning.\n",
    "\n",
    "> * What do we mean by a 'feature' in a machine learning model?\n",
    "> * What is the main problem with overfitting?\n",
    "> * Explain the connection between the bias-variance trade-off and overfitting/underfitting.\n",
    "> * The `Luke is for leukemia` on page 145 in the reading is a great example of why accuracy is not a good measure in very unbalanced problems. You know about the incidents dataset we've been working with. Try to come up with a similar example based on the data we've been working with today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scikit-learn\n",
    "\n",
    "In this section we introduce scikit-learn, `sklearn`. The best way to learn about any Python package, is to find a good tutorial and run through it to get an intuition for the syntax and how it's usage is intended (we've already done this with `pandas`, remember). \n",
    "\n",
    "The amazing package `sklearn` is state-of-the-art machine learning for Python. It's used in companies big and small all over the world and in lots of academic papers. To day we'll run through a couple of tutorials just to get you started.\n",
    "\n",
    "We start with a high level overview presented in [this tutorial](https://scikit-learn.org/stable/tutorial/basic/tutorial.html). **Try it out**: Read/work througH the first three sections (*Machine learning: the problem setting*, *Loading an example dataset*, *Learning and predicting*) to get a sense of data types and syntax.\n",
    "\n",
    "> *Exercise*: Did you read the text?\n",
    ">\n",
    "> * Describe in your own words how data is organized in `sklearn` (how does a *dataset* work according to the tutorial)?\n",
    "> * What is the dimensionality of the `.data` part of a dataset and what is the size of each dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to work through a [tutorial on text analytics](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html). You might wonder, why text. Well, there are two reasons. Firstly, this is a great tutorial that introduces various concepts that are useful for you guys to know about, so even if text isn't really part of the course - the tutorial still sets you up to be excellent users of `sklearn`. Secondly, it's not a bad thing to know about text analysis. Even in this class. This could be something you might like to use in the final project. And now you have a great place to go if you want to dig into some textual data.\n",
    "\n",
    "We won't do the whole tutorial. **Try it out**: I'd like you to work thorough up to and including the section *Building a pipeline*.\n",
    "\n",
    "> *Exercise*: Did you do the work?\n",
    ">\n",
    "> * Describe in your own words the dataset used in the tutorial. \n",
    "> * Investigate further: what kind of folder/file structure does the `sklearn.datasets.load_files` function expect?\n",
    "> * What is the \"bag-of-words\" representation of text? How does this strategy turn text into data of the kind described above?\n",
    "> * (Don't worry too much about tokenization and TF-IDF for now, but do check out those part if you want to use real text analysis later)\n",
    "> * Once you've built the classifier, play around with it a bit. Describe the content of the `predicted` variable.\n",
    "\n",
    "\n",
    "You can find an overview of all tutorials here https://scikit-learn.org/stable/tutorial/index.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to work with a real algorithm. We'll take the simplest machine learning scheme in the universe. Although it's simple, it is still often useful (as we shall see when we use it to analyze crime data). It's called *K nearest neighbors*.\n",
    "\n",
    "We start by Ole introducing the idea.\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/OE159z8kC-Y/0.jpg)](https://www.youtube.com/watch?v=OE159z8kC-Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ole on K-nearest-neighbors\n",
    "# YouTubeVideo(\"OE159z8kC-Y\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read about it. \n",
    "\n",
    "*Reading*: Again we turn to DSFS, this time chapter 12, as an intro to the KNN algorithm. It's on DTU Learn, under \"Lecture 6 reading\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Warm up exercises*: K-nearest-neighbors\n",
    "> \n",
    "> How does K-nearest-neighbors work? Explain in your own words.\n",
    "Explain in your own words: What is the curse of dimensionality? Use figure 12-6 in DSFS as part of your explanation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start working with the crime data. Here's a little exercise\n",
    "\n",
    "\n",
    "> *Exercise*: K-nearest-neighbors map.\n",
    ">\n",
    "> We know from last week's exercises that the focus crimes `PROSTITUTION`, `DRUG/NARCOTIC` and `DRIVING UNDER THE INFLUENCE` tend to be concentrated in certain neighborhoods, so we focus on those crime types since they will make the most sense a KNN - map.\n",
    "> \n",
    "> * Begin by using `folium` (see Week4) to plot all incidents of the three crime types on their own map. This will give you an idea of how the varioius crimes are distributed across the city.\n",
    "> * Next, it's time to set up your model based on the actual data. I recommend that you try out `sklearn`'s `KNeighborsClassifier`. For an intro, start with [this tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html) and follow the link to get a sense of the usage.\n",
    ">   * You don't have to think a lot about testing/trainig and accuracy for this exercise. We're mostly interested in creating a map that's not too problematic. But do calculate the number of observations of each crime-type respectively. You'll find that the levels of each crime varies (lots of drug arrests, an intermediate amount of prostitiution registered, and very little drunk driving in the dataset). Since the algorithm classifies each point according to it's neighbors, *what could a consequence of this imbalance in the number of examples from each class mean for your map*?\n",
    ">   * You can make the dataset 'balanced' by grabbing an equal number of examples from each crime category. \n",
    ">       * How do you expect that will change the KNN result? \n",
    ">       * In which situations is the balanced map useful - \n",
    ">       * When is the map where data is in proportion to occurrences useful? \n",
    ">       * Choose which map you will work on in the following.\n",
    "> * Now create an approximately square grid of point that runs over SF. You get to decide the grid-size, but I recommend somewhere between $50\\times50$ and $100\\times100$ points. I recommend using `folium` for this task.\n",
    "> * Visualize your model by coloring the grid, coloring each grid point according to it's category. Create a plot of this kind for models where each point is colored according to the majority of its $5$, $10$, and $30$ nearest neighbors. Describe what happens to the map as you increase the number of neighbors, `K`. \n",
    "> * To see an example, [click here](https://raw.githubusercontent.com/suneman/socialdata2021/master/files/KNN-example.png). This one is a 100x100 grid based on crimes from 1st January 2017 until the end of 2018. And the categories are narcotics, prostitution and vehicle theft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
