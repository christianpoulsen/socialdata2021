{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2.\n",
    "\n",
    "## Formalia:\n",
    "\n",
    "Please read the [assignment overview page](https://github.com/suneman/socialdata2021/wiki/Assignment-1-and-2) carefully before proceeding. This page contains information about formatting (including formats etc), group sizes, and many other aspects of handing in the assignment. \n",
    "\n",
    "_If you fail to follow these simple instructions, it will negatively impact your grade!_\n",
    "\n",
    "**Due date and time**: The assignment is due on Monday April 5th, 2021 at 23:55. Hand in your files via [`http://peergrade.io`](http://peergrade.io/).\n",
    "\n",
    "**Peergrading date and time**: _Remember that after handing in you have a week to evaluate a few assignments written by other members of the class_. Thus, the peer evaluations are due on Monday April 12th, 2021 at 23:55. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Questions to text and lectures.\n",
    "\n",
    "A) Please answer my questions to the Segal and Heer paper we read during lecture 7 and 8.\n",
    "\n",
    "* What is the *Oxford English Dictionary's* defintion of a narrative?\n",
    "* What is your favorite visualization among the examples in section 3? Explain why in a few words.\n",
    "* What's the point of Figure 7?\n",
    "* Use Figure 7 to find the most common design choice within each category for the Visual narrative and Narrative structure (the categories within visual narrative are 'visual structuring', 'highlighting', etc).\n",
    "* Check out Figure 8 and section 4.3. What is your favorite genre of narrative visualization? Why? What is your least favorite genre? Why?\n",
    "\n",
    "\n",
    "B) Also please answer the questions to my talk on [explanatory data visualization](https://www.youtube.com/watch?v=yHKYMGwefso)\n",
    "\n",
    "* What are the three key elements to keep in mind when you design an explanatory visualization?\n",
    "* In the video I talk about (1) *overview first*,  (2) *zoom and filter*,  (3) *details on demand*. \n",
    "  - Go online and find a visualization that follows these principles (don't use one from the video). \n",
    "  - Explain how it does achieves (1)-(3). It might be useful to use screenshots to illustrate your explanation.\n",
    "* Explain in your own words: How is explanatory data analysis different from exploratory data analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Random forest and weather\n",
    "\n",
    "The aim here is to recreate the work you did in Part 1-3 of the Week 7 lecture. I've phrased things differently relative to the exercise to make the purpose more clear. \n",
    "\n",
    "Part 2A: Random forest binary classification. \n",
    "* Using the and instructions and material from Week 7, build a *random forest* classifier to distinguish between two types (you choose) of crime using on spatio-temporal (where/when) features of data describing the two crimes. When you're done, you should be able to give the classifier a place and a time, and it should tell you which of the two  types of crime happened there.\n",
    "  - Explain about your choices for training/test data, features, and encoding. (You decide how to present your results, but here are some example topics to consider: Did you balance the training data? What are the pros/cons of balancing? Do you think your model is overfitting? Did you choose to do cross-validation? Which specific features did you end up using? Why? Which features (if any) did you one-hot encode? Why ... or why not?))\n",
    "  - Report accuracy. Discuss the model performance.\n",
    "  \n",
    "  \n",
    "Part 2B: Info from weather features.\n",
    "* Now add features from weather data to your random forest. \n",
    "  - Report accuracy. \n",
    "  - Discuss how the model performance changes relative to the version with no weather data.\n",
    "  - Discuss what you have learned about crime from including weather data in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "crimes = pd.read_csv(\"../incidents.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from datetime import datetime\n",
    "\n",
    "# Burglary samples: 91067,  Fraud samples: 41348\n",
    "\n",
    "focuscrimes = [\"BURGLARY\", \"FRAUD\"]\n",
    "\n",
    "crimes = crimes[crimes[\"Category\"].isin(focuscrimes)]\n",
    "\n",
    "crimes[\"Date_Time\"] = pd.to_datetime(crimes[\"Date\"] + \" \" + crimes[\"Time\"])\n",
    "crimes[\"Year\"] = crimes[\"Date_Time\"].dt.year\n",
    "crimes[\"Month\"] = crimes[\"Date_Time\"].dt.month\n",
    "crimes[\"Hour\"] = crimes[\"Date_Time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35912, 39)\n",
      "(16703, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PdId</th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Incident Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>...</th>\n",
       "      <th>Areas of Vulnerability, 2016 2 2</th>\n",
       "      <th>Central Market/Tenderloin Boundary 2 2</th>\n",
       "      <th>Central Market/Tenderloin Boundary Polygon - Updated 2 2</th>\n",
       "      <th>HSOC Zones as of 2018-06-05 2 2</th>\n",
       "      <th>OWED Public Spaces 2 2</th>\n",
       "      <th>Neighborhoods 2</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13085582009320</td>\n",
       "      <td>130855820</td>\n",
       "      <td>9320</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>CREDIT CARD, THEFT BY USE OF</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10/08/2013</td>\n",
       "      <td>21:11</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2013-10-08 21:11:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>13007111705041</td>\n",
       "      <td>130071117</td>\n",
       "      <td>5041</td>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>BURGLARY OF RESIDENCE, FORCIBLE ENTRY</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01/25/2013</td>\n",
       "      <td>07:45</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2013-01-25 07:45:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>12020159005073</td>\n",
       "      <td>120201590</td>\n",
       "      <td>5073</td>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>BURGLARY, UNLAWFUL ENTRY</td>\n",
       "      <td>Monday</td>\n",
       "      <td>03/05/2012</td>\n",
       "      <td>10:34</td>\n",
       "      <td>RICHMOND</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012-03-05 10:34:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>13083397305071</td>\n",
       "      <td>130833973</td>\n",
       "      <td>5071</td>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>BURGLARY, FORCIBLE ENTRY</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10/01/2013</td>\n",
       "      <td>08:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2013-10-01 08:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>13090015205013</td>\n",
       "      <td>130900152</td>\n",
       "      <td>5013</td>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>BURGLARY OF APARTMENT HOUSE, UNLAWFUL ENTRY</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10/22/2013</td>\n",
       "      <td>15:35</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2013-10-22 15:35:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PdId  IncidntNum  Incident Code  Category  \\\n",
       "5    13085582009320   130855820           9320     FRAUD   \n",
       "68   13007111705041   130071117           5041  BURGLARY   \n",
       "93   12020159005073   120201590           5073  BURGLARY   \n",
       "133  13083397305071   130833973           5071  BURGLARY   \n",
       "162  13090015205013   130900152           5013  BURGLARY   \n",
       "\n",
       "                                        Descript DayOfWeek        Date   Time  \\\n",
       "5                   CREDIT CARD, THEFT BY USE OF   Tuesday  10/08/2013  21:11   \n",
       "68         BURGLARY OF RESIDENCE, FORCIBLE ENTRY    Friday  01/25/2013  07:45   \n",
       "93                      BURGLARY, UNLAWFUL ENTRY    Monday  03/05/2012  10:34   \n",
       "133                     BURGLARY, FORCIBLE ENTRY   Tuesday  10/01/2013  08:00   \n",
       "162  BURGLARY OF APARTMENT HOUSE, UNLAWFUL ENTRY   Tuesday  10/22/2013  15:35   \n",
       "\n",
       "    PdDistrict      Resolution  ... Areas of Vulnerability, 2016 2 2  \\\n",
       "5         PARK            NONE  ...                              1.0   \n",
       "68        PARK            NONE  ...                              1.0   \n",
       "93    RICHMOND            NONE  ...                              2.0   \n",
       "133   NORTHERN            NONE  ...                              1.0   \n",
       "162   NORTHERN  ARREST, BOOKED  ...                              1.0   \n",
       "\n",
       "     Central Market/Tenderloin Boundary 2 2  \\\n",
       "5                                       NaN   \n",
       "68                                      NaN   \n",
       "93                                      NaN   \n",
       "133                                     NaN   \n",
       "162                                     NaN   \n",
       "\n",
       "     Central Market/Tenderloin Boundary Polygon - Updated 2 2  \\\n",
       "5                                                  NaN          \n",
       "68                                                 NaN          \n",
       "93                                                 NaN          \n",
       "133                                                NaN          \n",
       "162                                                NaN          \n",
       "\n",
       "    HSOC Zones as of 2018-06-05 2 2  OWED Public Spaces 2 2  Neighborhoods 2  \\\n",
       "5                               NaN                     NaN             13.0   \n",
       "68                              NaN                     NaN            112.0   \n",
       "93                              NaN                     NaN              8.0   \n",
       "133                             NaN                     NaN            102.0   \n",
       "162                             NaN                     NaN            105.0   \n",
       "\n",
       "              Date_Time  Year  Month  Hour  \n",
       "5   2013-10-08 21:11:00  2013     10    21  \n",
       "68  2013-01-25 07:45:00  2013      1     7  \n",
       "93  2012-03-05 10:34:00  2012      3    10  \n",
       "133 2013-10-01 08:00:00  2013     10     8  \n",
       "162 2013-10-22 15:35:00  2013     10    15  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_in_range = crimes[crimes[\"Year\"].between(2012, 2017, inclusive=True)]\n",
    "burglary = crimes_in_range[crimes_in_range[\"Category\"].isin([focuscrimes[0]])]\n",
    "fraud = crimes_in_range[crimes_in_range[\"Category\"].isin([focuscrimes[1]])]\n",
    "\n",
    "print(burglary.shape)\n",
    "print(fraud.shape)\n",
    "\n",
    "crimes_in_range.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 15000\n",
    "\n",
    "# Create balanced data set\n",
    "type1 = burglary.sample(sample_size)\n",
    "type2 = fraud.sample(sample_size)\n",
    "\n",
    "crime_df = pd.concat([type1, type2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (22500, 19)\n",
      "Training Labels Shape: (22500,)\n",
      "Testing Features Shape: (7500, 19)\n",
      "Testing Labels Shape: (7500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-59dc60f2f722>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"Category\"] = le.fit_transform(features[\"Category\"])\n"
     ]
    }
   ],
   "source": [
    "features = crime_df[[\"Category\", \"DayOfWeek\", \"Month\", \"Hour\", \"PdDistrict\"]]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "features[\"Category\"] = le.fit_transform(features[\"Category\"])\n",
    "\n",
    "# One-hot encode the categorical data\n",
    "features = pd.get_dummies(features, columns=[\"DayOfWeek\", \"PdDistrict\"])\n",
    "\n",
    "# Labels will be the values we want to predict\n",
    "labels = np.array(features[\"Category\"])\n",
    "\n",
    "# We remove the labels from the crime dataframe to get all the values we need for the features\n",
    "features = features.drop('Category', axis=1)\n",
    "\n",
    "# We save the feature names for later\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert the dataframe to a numpy array so we can work with the features\n",
    "features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Max Average Tree Depth: 29.96969696969697\n",
      "Training\n",
      "Mean Absolute Error: 0.17 degrees.\n",
      "Accuracy:  82.87555555555556 %\n",
      "\n",
      "Testing\n",
      "Mean Absolute Error: 0.41 degrees.\n",
      "TeAccuracy:  59.17333333333333 %\n",
      "\n",
      "Max Depth 3\n",
      "Training\n",
      "Mean Absolute Error: 0.4 degrees.\n",
      "Accuracy:  59.96444444444444 %\n",
      "\n",
      "Testing\n",
      "Mean Absolute Error: 0.4 degrees.\n",
      "TeAccuracy:  60.160000000000004 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "no_max_classifier = RandomForestClassifier(n_estimators=99, random_state=42)\n",
    "no_max_classifier.fit(train_features, train_labels)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=99, random_state=42, max_depth=3)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "print(\"No Max Average Tree Depth:\", np.mean([estimator.get_depth() for estimator in no_max_classifier.estimators_]))\n",
    "\n",
    "no_max_train_predictions = no_max_classifier.predict(train_features)\n",
    "print(\"Training\")\n",
    "print('Mean Absolute Error:', round(mean_absolute_error(train_labels, no_max_train_predictions), 2), 'degrees.')\n",
    "print(\"Accuracy: \", 100 * no_max_classifier.score(train_features, train_labels), \"%\\n\")\n",
    "\n",
    "no_max_predictions = no_max_classifier.predict(test_features)\n",
    "print(\"Testing\")\n",
    "print('Mean Absolute Error:', round(mean_absolute_error(test_labels, no_max_predictions), 2), 'degrees.')\n",
    "print(\"TeAccuracy: \", 100 * no_max_classifier.score(test_features, test_labels), \"%\\n\")\n",
    "\n",
    "\n",
    "print(\"Max Depth 3\")\n",
    "\n",
    "train_predictions = classifier.predict(train_features)\n",
    "print(\"Training\")\n",
    "print('Mean Absolute Error:', round(mean_absolute_error(train_labels, train_predictions), 2), 'degrees.')\n",
    "print(\"Accuracy: \", 100 * classifier.score(train_features, train_labels), \"%\\n\")\n",
    "\n",
    "predictions = classifier.predict(test_features)\n",
    "print(\"Testing\")\n",
    "print('Mean Absolute Error:', round(mean_absolute_error(test_labels, predictions), 2), 'degrees.')\n",
    "print(\"TeAccuracy: \", 100 * classifier.score(test_features, test_labels), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2A\n",
    "\n",
    "**Did you balance the training data? What are the pros/cons of balancing?**\n",
    "\n",
    "The dataset is balanced with 20000 randomly picked samples from each crime category, as to ensure the crime are distributed equally over time with no favor of one over the other.\n",
    "\n",
    "**Do you think your model is overfitting?**\n",
    "\n",
    "Initially where the classifier had no maximum depth, the training accuracy was near 89% where test accuracy was at 52-53%. Together with a avg. tree depth of around 45 of a dataset with 18 feautures, it seems safe to assume that the model was overfitting, as it clearly shows it did not generalize well from the training data to the testing data.\n",
    "\n",
    "However, with a maximum depth of 3, a higher accuracy is reached but with a drastical smaller tree size, which could indicate a better fitted model.\n",
    "\n",
    "**Did you choose to do cross-validation?**\n",
    "\n",
    "To error estimate the classifier, the Holdout Method is used by creating training and testing/validation datasets. The testing datasets are then used to calculate the mean accuracy of the classifier.\n",
    "\n",
    "**Which specific features did you end up using? Why?**\n",
    "\n",
    "The features used are \"DayOfWeek\", \"Date\", \"Time\", and \"PdDistrict\", because they tell something about the time and place of the crime.\n",
    "\n",
    "**Which features (if any) did you one-hot encode? Why ... or why not?))**\n",
    "\n",
    "The features to be one-hot encoded was \"DayOfWeek\" and \"PdDistrict\", where the crime category was just label encoded. Both \"DayOfWeek\" and \"PdDistrict\" includes categorical variables that should be converted to binary data which the machine can understand without preferring one over the other, why Pandas' get_dummies function is used.\n",
    "\n",
    "Because the crime category is what should be predicted, these are not converted to binary data, but are just given a numeric representation using Sklearn's LabelEncoder.\n",
    "\n",
    "The \"Date\" and \"Time\" features are also kind of included. When the raw crime data is loaded into a dataframe, the columns are just treated as strings. We want to use them to determine how time influceses the crimes. To make the machine understand this, however, the columns are merged together to a datetime column \"Date_Time\" where the dates are converted to their ordinal numeric values.\n",
    "At the time this seemed smart, but after doing some thinking, it would probably have been better to split the date times up into something like; year, month, day, hour, minute or something, as humans, and therefor crimes, follow more patterns of our gregorian calendar rather than a UNIX timestamp...\n",
    "\n",
    "**Report accuracy. Discuss the model performance.**\n",
    "\n",
    "Well, the accuracy is around 57% for the Random Forest classifier, an 14 % better accuracy of the baseline of 50/50. This is probably not good enough for any practical application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"../weather_data.csv\")\n",
    "\n",
    "# Format date and time for easy processing and training\n",
    "weather[\"Date_Time\"] = pd.to_datetime(weather[\"date\"])\n",
    "weather[\"Year\"] = weather[\"Date_Time\"].dt.year\n",
    "weather[\"Month\"] = weather[\"Date_Time\"].dt.month\n",
    "weather[\"Hour\"] = weather[\"Date_Time\"].dt.hour\n",
    "\n",
    "# Fix naming\n",
    "weather[\"Temperature\"] = weather[\"temperature\"]\n",
    "weather[\"Humidity\"] = weather[\"humidity\"]\n",
    "weather[\"Wind_Direction\"] = weather[\"wind_direction\"]\n",
    "weather[\"Wind_Speed\"] = weather[\"wind_speed\"]\n",
    "weather[\"Weather\"] = weather[\"weather\"]\n",
    "weather[\"Pressure\"] = weather[\"pressure\"]\n",
    "\n",
    "# Drop the columns we don't need\n",
    "weather = weather.drop([\"Date_Time\", \"temperature\", \"weather\", \"pressure\", \"humidity\", \"wind_direction\", \"wind_speed\", \"date\"], axis=1)\n",
    "\n",
    "# One-hot encode the categorical data\n",
    "weather_df = pd.get_dummies(weather, columns=[\"Weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge the weather and crime dataframes together!\n",
    "\n",
    "merged = pd.merge(crime_df, weather_df, how=\"left\", on=[\"Month\", \"Hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crimes:  (30000, 19)\n",
      "Merged:  (4619871, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayOfWeek_Friday</th>\n",
       "      <th>DayOfWeek_Monday</th>\n",
       "      <th>DayOfWeek_Saturday</th>\n",
       "      <th>DayOfWeek_Sunday</th>\n",
       "      <th>DayOfWeek_Thursday</th>\n",
       "      <th>DayOfWeek_Tuesday</th>\n",
       "      <th>DayOfWeek_Wednesday</th>\n",
       "      <th>PdDistrict_BAYVIEW</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather_scattered clouds</th>\n",
       "      <th>Weather_shower rain</th>\n",
       "      <th>Weather_sky is clear</th>\n",
       "      <th>Weather_smoke</th>\n",
       "      <th>Weather_squalls</th>\n",
       "      <th>Weather_thunderstorm</th>\n",
       "      <th>Weather_thunderstorm with heavy rain</th>\n",
       "      <th>Weather_thunderstorm with light rain</th>\n",
       "      <th>Weather_thunderstorm with rain</th>\n",
       "      <th>Weather_very heavy rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Hour  DayOfWeek_Friday  DayOfWeek_Monday  DayOfWeek_Saturday  \\\n",
       "0      3     0                 0                 0                   0   \n",
       "1      3     0                 0                 0                   0   \n",
       "2      3     0                 0                 0                   0   \n",
       "3      3     0                 0                 0                   0   \n",
       "4      3     0                 0                 0                   0   \n",
       "\n",
       "   DayOfWeek_Sunday  DayOfWeek_Thursday  DayOfWeek_Tuesday  \\\n",
       "0                 0                   0                  0   \n",
       "1                 0                   0                  0   \n",
       "2                 0                   0                  0   \n",
       "3                 0                   0                  0   \n",
       "4                 0                   0                  0   \n",
       "\n",
       "   DayOfWeek_Wednesday  PdDistrict_BAYVIEW  ...  Weather_scattered clouds  \\\n",
       "0                    1                   0  ...                         1   \n",
       "1                    1                   0  ...                         0   \n",
       "2                    1                   0  ...                         0   \n",
       "3                    1                   0  ...                         0   \n",
       "4                    1                   0  ...                         0   \n",
       "\n",
       "   Weather_shower rain  Weather_sky is clear  Weather_smoke  Weather_squalls  \\\n",
       "0                    0                     0              0                0   \n",
       "1                    0                     0              0                0   \n",
       "2                    0                     0              0                0   \n",
       "3                    0                     0              0                0   \n",
       "4                    0                     0              0                0   \n",
       "\n",
       "   Weather_thunderstorm  Weather_thunderstorm with heavy rain  \\\n",
       "0                     0                                     0   \n",
       "1                     0                                     0   \n",
       "2                     0                                     0   \n",
       "3                     0                                     0   \n",
       "4                     0                                     0   \n",
       "\n",
       "   Weather_thunderstorm with light rain  Weather_thunderstorm with rain  \\\n",
       "0                                     0                               0   \n",
       "1                                     0                               0   \n",
       "2                                     0                               0   \n",
       "3                                     0                               0   \n",
       "4                                     0                               0   \n",
       "\n",
       "   Weather_very heavy rain  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Crimes: \", crime_df.shape)\n",
    "print(\"Merged: \", merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data visualization\n",
    "\n",
    "* Create the Bokeh visualization from Part 2 of the Week 8 Lecture, displayed in a beautiful `.gif` below. \n",
    "* Provide nice comments for your code. Don't just use the `# inline comments`, but the full Notebook markdown capabilities and explain what you're doing.\n",
    "\n",
    "![Movie](https://github.com/suneman/socialdataanalysis2020/blob/master/files/week8_1.gif?raw=true \"movie\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
